{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kk6_RDqvkmlh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_wav_files(directory):\n",
        "    wav_files = [file for file in os.listdir(directory) if file.endswith('.wav')]\n",
        "    text_files = [file for file in os.listdir(directory) if file.endswith('.txt')]\n",
        "    return wav_files, text_files\n",
        "\n",
        "\n",
        "data_dir = 'dataset'\n",
        "wav_files, text_files = list_wav_files(data_dir)\n",
        "print(wav_files, text_files)\n",
        "audio_files = wav_files\n",
        "transcripts = text_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un3P5u8XknSM",
        "outputId": "0d71bc86-c098-45a1-e2e0-7e9e1edd4b38"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['p1.wav', 'file2.wav', 'file1.wav', 'file4.wav', 'file3.wav'] ['file4.txt', 'file1.txt', 'p1.txt', 'file3.txt', 'file2.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path, max_len=100):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=40)\n",
        "    if mfccs.shape[1] < max_len:\n",
        "        pad_width = max_len - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfccs = mfccs[:, :max_len]\n",
        "    return mfccs.T"
      ],
      "metadata": {
        "id": "mrsnNK9nlNz9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 100  # Max length of the MFCC feature sequence\n",
        "features = np.array([extract_features(os.path.join(data_dir, f), max_len) for f in audio_files])"
      ],
      "metadata": {
        "id": "pUF4bmmblSyT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_texts = [open(os.path.join(data_dir, t)).read().strip() for t in transcripts]"
      ],
      "metadata": {
        "id": "MsDepZOelV1i"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(char_level=True)  # Character-level tokenizer\n",
        "tokenizer.fit_on_texts(transcript_texts)\n",
        "sequences = tokenizer.texts_to_sequences(transcript_texts)\n",
        "max_seq_length = max_len  # Ensure that max_seq_length matches max_len\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
        "num_classes = len(tokenizer.word_index) + 1\n",
        "labels = np.array([to_categorical(seq, num_classes=num_classes) for seq in padded_sequences])"
      ],
      "metadata": {
        "id": "XE03637qlZh4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Kk1daucblg1P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (max_len, 40)\n",
        "input_layer = Input(shape=input_shape)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)\n",
        "x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = TimeDistributed(Dense(num_classes, activation='softmax'))(x)\n",
        "model = Model(inputs=input_layer, outputs=x)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si-WaF7Hljm5",
        "outputId": "acd5e73a-0c96-4b1a-d840-fe9beca7a746"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 100, 40)]         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 100, 256)          173056    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDi  (None, 100, 128)          32896     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 100, 18)           2322      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 208274 (813.57 KB)\n",
            "Trainable params: 208274 (813.57 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek4tQ3u8ln1Z",
        "outputId": "941f5e56-35d0-4c24-8368-e17bd7b65b42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 7s 7s/step - loss: 3.2437 - accuracy: 0.0100 - val_loss: 2.8612 - val_accuracy: 0.4800\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 2.9016 - accuracy: 0.3950 - val_loss: 2.5924 - val_accuracy: 0.6700\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 2.6224 - accuracy: 0.5900 - val_loss: 2.3417 - val_accuracy: 0.9400\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 2.4130 - accuracy: 0.7300 - val_loss: 2.1048 - val_accuracy: 0.9500\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 2.1513 - accuracy: 0.8425 - val_loss: 1.8781 - val_accuracy: 0.9500\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 1.9371 - accuracy: 0.8825 - val_loss: 1.6555 - val_accuracy: 0.9500\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 1.7565 - accuracy: 0.8925 - val_loss: 1.4075 - val_accuracy: 0.9500\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 1.5045 - accuracy: 0.8950 - val_loss: 1.0930 - val_accuracy: 0.9500\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 1.2541 - accuracy: 0.8950 - val_loss: 0.7288 - val_accuracy: 0.9500\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.9485 - accuracy: 0.8950 - val_loss: 0.4745 - val_accuracy: 0.9500\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.6976 - accuracy: 0.8950 - val_loss: 0.3587 - val_accuracy: 0.9500\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.6098 - accuracy: 0.8950 - val_loss: 0.3188 - val_accuracy: 0.9500\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.5070 - accuracy: 0.8975 - val_loss: 0.3130 - val_accuracy: 0.9500\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 0.5011 - accuracy: 0.8950 - val_loss: 0.3142 - val_accuracy: 0.9500\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.4810 - accuracy: 0.8950 - val_loss: 0.3155 - val_accuracy: 0.9500\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.4647 - accuracy: 0.8925 - val_loss: 0.3152 - val_accuracy: 0.9500\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 0.4377 - accuracy: 0.8950 - val_loss: 0.3134 - val_accuracy: 0.9500\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.4019 - accuracy: 0.9025 - val_loss: 0.3104 - val_accuracy: 0.9500\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 156ms/step - loss: 0.4022 - accuracy: 0.8975 - val_loss: 0.3068 - val_accuracy: 0.9500\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.3886 - accuracy: 0.9000 - val_loss: 0.3031 - val_accuracy: 0.9500\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.4065 - accuracy: 0.8925 - val_loss: 0.2994 - val_accuracy: 0.9500\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3614 - accuracy: 0.9025 - val_loss: 0.2948 - val_accuracy: 0.9500\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 0.3506 - accuracy: 0.9025 - val_loss: 0.2896 - val_accuracy: 0.9500\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.3346 - accuracy: 0.9025 - val_loss: 0.2866 - val_accuracy: 0.9500\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.3286 - accuracy: 0.9050 - val_loss: 0.2842 - val_accuracy: 0.9500\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.3312 - accuracy: 0.9025 - val_loss: 0.2814 - val_accuracy: 0.9500\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3237 - accuracy: 0.9025 - val_loss: 0.2783 - val_accuracy: 0.9500\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 0.3439 - accuracy: 0.9050 - val_loss: 0.2733 - val_accuracy: 0.9500\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.3075 - accuracy: 0.9100 - val_loss: 0.2686 - val_accuracy: 0.9500\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.2875 - accuracy: 0.9100 - val_loss: 0.2653 - val_accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
        "model.save('speech_recognition_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cga-ipCelx2g",
        "outputId": "1657e268-cef3-40ee-f8d6-117513e7816c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 95ms/step - loss: 0.2653 - accuracy: 0.9500\n",
            "Test accuracy: 95.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_transcript(file_path, model, tokenizer, max_len=100):\n",
        "    features = extract_features(file_path, max_len)\n",
        "    features = features[np.newaxis, ...]  # Add batch dimension\n",
        "    prediction = model.predict(features)\n",
        "    predicted_sequence = np.argmax(prediction, axis=-1).flatten()\n",
        "    predicted_text = tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
        "    return predicted_text\n",
        "\n",
        "# Example usage\n",
        "predicted_transcript = predict_transcript(os.path.join(data_dir, 'p1.wav'), model, tokenizer)\n",
        "print(\"Predicted Transcript:\", predicted_transcript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdm9sHCVl3hR",
        "outputId": "11ca8fac-0d22-4370-cf0c-c101406e99a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Predicted Transcript:          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uU47zGbcl-sv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}